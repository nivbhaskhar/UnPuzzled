{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FineTuning ResNet\n",
    "\n",
    "Recall that we call a tuple of puzzle pieces (P, Q) (order matters!) to be __left-right adjacent__ if when P is placed to the left of Q, P's right edge is adjacent to Q's left edge.\n",
    "\n",
    "Instead of building a model from scratch, we _finetune_ an exisiting model ResNet18. That is, we take ResNet18's architecture and reshape its last fully connected layer so as to give outputs in the shapes we require. \n",
    "\n",
    "\n",
    "We will then train this modified model __ResNetFT__ to solve our _checking_left_right_adjacency_problem_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import os\n",
    "\n",
    "import pprint\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "# generate random integer values\n",
    "from random import seed\n",
    "from random import randint\n",
    "import numpy as np\n",
    "from random import sample\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from torchvision import transforms, utils, models\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "#from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "#import csv\n",
    "from time import time\n",
    "\n",
    "\n",
    "import sys\n",
    "import Checking_adjacency_dataset as cad\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our earlier defined custom  _AdjacencyDataset_. Recall that we generate our data set from the CUB-200 dataset. \n",
    "\n",
    "__Input for AdjacencyDataset__\n",
    "<ul>\n",
    "    <li>root_dir : the root directory where the CUB-200 images are stored </li>\n",
    "<li> sq_puzzle_piece_dim : the dimension of the square puzzle piece (recall we cut the original image into uniform square puzzle pieces) </li>\n",
    "    <li> size_of_buffer : the buffer size for our shuffle_iterator</li>\n",
    "    <li> model_dim : input size for the model</li>\n",
    " </ul>\n",
    " \n",
    "__Output of AdjacencyDataset__\n",
    "<ul>\n",
    "    <li> juxtaposed_pieces_torchtensor : cropped (from the middle of the juxtaposed pieces) square rescaled piece with width, height = model_dim </li>\n",
    "    <li> label : 1 if left-right adjacent, 0 if not</li>\n",
    "</ul>\n",
    "\n",
    "Each data point therefore looks like (juxtaposed_pieces_torchtensor, label) the torchtensor has dimensions 3 x model_dim x model_dim (3 because RGB image, so 3 channels)\n",
    "The label is 1 if the pieces are left-right adjacent else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_root_dir = os.getenv(\"MY_ROOT_DIR\")\n",
    "my_sq_puzzle_piece_dim = 100\n",
    "my_size_of_buffer = 1000\n",
    "my_model_dim = 224\n",
    "my_batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_resnetft_adj_dataset = cad.AdjacencyDataset(my_root_dir, \n",
    "                                                      my_sq_puzzle_piece_dim, \n",
    "                                                      my_size_of_buffer, my_model_dim)\n",
    "\n",
    "\n",
    "\n",
    "train_resnetft_adj_dataloader = DataLoader(train_resnetft_adj_dataset, \n",
    "                                               my_batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 224, 224]) torch.Size([5])\n",
      "tensor([1, 1, 1, 1, 0])\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0.4812)\n"
     ]
    }
   ],
   "source": [
    "juxtaposed_pieces_torchtensor, label = next(iter(train_resnetft_adj_dataloader))\n",
    "print(juxtaposed_pieces_torchtensor.shape, label.shape)\n",
    "print(label)\n",
    "print(torch.min(juxtaposed_pieces_torchtensor), torch.max(juxtaposed_pieces_torchtensor))\n",
    "print(torch.mean(juxtaposed_pieces_torchtensor.view(-1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_resnet(no_of_classes, feature_extract, use_pretrained=True):\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "    model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    no_of_features = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(no_of_features, no_of_classes)    \n",
    "    return model_ft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters_to_update(model_name, model, feature_extract=False):\n",
    "    params = list(model.parameters())\n",
    "    if model_name==\"ResNetFT\":\n",
    "        if feature_extract:\n",
    "            print(\"Feature extracting from ResNet - Expect less number of parameters to learn!\")\n",
    "            params = []\n",
    "            for name,param in model.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    params.append(param)\n",
    "                    print(\"\\t\",name)\n",
    "        else:\n",
    "            print(\"Fine tuning ResNet - Expect more number of parameters to learn!\")\n",
    "            for name,param in model.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    print(\"\\t\",name)\n",
    "    elif model_name==\"FromScratch\":\n",
    "        print(\"Using FromScratch - Expect more number of parameters to learn!\")\n",
    "        for name,param in model.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    print(\"\\t\",name)\n",
    "        \n",
    "    print(f\"No_of_parameters to learn : {len(params)}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A test ResNetFT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_classes = 2\n",
    "#If finetuning, feature_extract = False, else True\n",
    "feature_extract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = reshape_resnet(no_of_classes, feature_extract, use_pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tuning ResNet - Expect more number of parameters to learn!\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n",
      "No_of_parameters to learn : 62\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x12527bdd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_to_update(\"ResNetFT\", test_model, feature_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0189, -0.0148,  0.0311,  ...,  0.0053,  0.0298, -0.0299],\n",
      "        [-0.0359, -0.0122, -0.0362,  ..., -0.0415, -0.0339, -0.0433]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0251, -0.0067], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(test_model.fc.weight)\n",
    "print(test_model.fc.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "juxtaposed_pieces_torchtensor, label = next(iter(train_resnetft_adj_dataloader))\n",
    "test_output_for_resnetft = test_model(juxtaposed_pieces_torchtensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2232,  0.3393],\n",
       "        [ 0.4366, -0.1868],\n",
       "        [-0.4116, -0.6638],\n",
       "        [ 0.5400,  0.6125],\n",
       "        [ 0.2978, -0.6460]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output_for_resnetft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, predictions = torch.max(test_output_for_resnetft, axis = 1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3393,  0.4366, -0.4116,  0.6125,  0.2978], grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reshaped \"ResNet18\", whose outputs are vectors of the shape (a_0, a_1). We interpret $a_i$ to be the _score_ given by the model for the label being i. We interpret higher scores to mean higher chance of the label in truth being i.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
